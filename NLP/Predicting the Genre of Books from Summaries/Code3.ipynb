{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manjiri Pendharkar - 45933219"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github url - https://github.com/MQCOMP2200-S2-2020/portfolio-2020-manjiri2077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Genre of Books from Summaries\n",
    "\n",
    "We'll use a set of book summaries from the [CMU Book Summaries Corpus](http://www.cs.cmu.edu/~dbamman/booksummaries.html) in this experiment.  This contains a large number of summaries (16,559) and includes meta-data about the genre of the books taken from Freebase.  Each book can have more than one genre and there are 227 genres listed in total.  To simplify the problem of genre prediction we will select a small number of target genres that occur frequently in the collection and select the books with these genre labels.  This will give us one genre label per book. \n",
    "\n",
    "Your goal in this portfolio is to take this data and build predictive models to classify the books into one of the five target genres.  You will need to extract suitable features from the texts and select suitable models to classify them. You should build and evaluate at least TWO models and compare the prediction results.\n",
    "\n",
    "You should report on each stage of your experiment as you work with the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The first task is to read the data. It is made available in tab-separated format but has no column headings. We can use `read_csv` to read this but we need to set the separator to `\\t` (tab) and supply the column names.  The names come from the [ReadMe](data/booksummaries/README.txt) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>fid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>/m/0sww</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td>David Hume</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wid      fid                                      title           author  \\\n",
       "0   620  /m/0hhy                                Animal Farm    George Orwell   \n",
       "1   843  /m/0k36                         A Clockwork Orange  Anthony Burgess   \n",
       "2   986  /m/0ldx                                 The Plague     Albert Camus   \n",
       "3  1756  /m/0sww  An Enquiry Concerning Human Understanding       David Hume   \n",
       "4  2080  /m/0wkt                       A Fire Upon the Deep     Vernor Vinge   \n",
       "\n",
       "         date                                             genres  \\\n",
       "0  1945-08-17  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1        1962  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2        1947  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "3                                                                  \n",
       "4              {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['wid', 'fid', 'title', 'author', 'date', 'genres', 'summary']\n",
    "\n",
    "books = pd.read_csv(\"data/booksummaries.txt\", sep=\"\\t\", header=None, names=names, keep_default_na=False)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next filter the data so that only our target genre labels are included and we assign each text to just one of the genre labels.  It's possible that one text could be labelled with two of these labels (eg. Science Fiction and Fantasy) but we will just assign one of those here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_genres = [\"Children's literature\",\n",
    "                 'Science Fiction',\n",
    "                 'Novel',\n",
    "                 'Fantasy',\n",
    "                 'Mystery']\n",
    "\n",
    "# create a Series of empty strings the same length as the list of books\n",
    "genre = pd.Series(np.repeat(\"\", books.shape[0]))\n",
    "# look for each target genre and set the corresponding entries in the genre series to the genre label\n",
    "for g in target_genres:\n",
    "    genre[books['genres'].str.contains(g)] = g\n",
    "\n",
    "# add this to the book dataframe and then select only those rows that have a genre label\n",
    "# drop some useless columns\n",
    "books['genre'] = genre\n",
    "genre_books = books[genre!=''].drop(['genres', 'fid', 'wid'], axis=1)\n",
    "\n",
    "genre_books.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "      <td>Children's literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "      <td>Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "      <td>Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1968</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title             author        date  \\\n",
       "0           Animal Farm      George Orwell  1945-08-17   \n",
       "1    A Clockwork Orange    Anthony Burgess        1962   \n",
       "2            The Plague       Albert Camus        1947   \n",
       "4  A Fire Upon the Deep       Vernor Vinge               \n",
       "6  A Wizard of Earthsea  Ursula K. Le Guin        1968   \n",
       "\n",
       "                                             summary                  genre  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  Children's literature  \n",
       "1   Alex, a teenager living in near-future Englan...                  Novel  \n",
       "2   The text of The Plague is divided into five p...                  Novel  \n",
       "4   The novel posits that space around the Milky ...                Fantasy  \n",
       "6   Ged is a young boy on Gont, one of the larger...                Fantasy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children's literature</th>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novel</th>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  author  date  summary\n",
       "genre                                              \n",
       "Children's literature   1092    1092  1092     1092\n",
       "Fantasy                 2311    2311  2311     2311\n",
       "Mystery                 1396    1396  1396     1396\n",
       "Novel                   2258    2258  2258     2258\n",
       "Science Fiction         1897    1897  1897     1897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many books we have in each genre category\n",
    "genre_books.groupby('genre').count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit(list(genre_books['genre'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "      <td>Children's literature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "      <td>Novel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "      <td>Novel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1968</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title             author        date  \\\n",
       "0           Animal Farm      George Orwell  1945-08-17   \n",
       "1    A Clockwork Orange    Anthony Burgess        1962   \n",
       "2            The Plague       Albert Camus        1947   \n",
       "4  A Fire Upon the Deep       Vernor Vinge               \n",
       "6  A Wizard of Earthsea  Ursula K. Le Guin        1968   \n",
       "\n",
       "                                             summary                  genre  \\\n",
       "0   Old Major, the old boar on the Manor Farm, ca...  Children's literature   \n",
       "1   Alex, a teenager living in near-future Englan...                  Novel   \n",
       "2   The text of The Plague is divided into five p...                  Novel   \n",
       "4   The novel posits that space around the Milky ...                Fantasy   \n",
       "6   Ged is a young boy on Gont, one of the larger...                Fantasy   \n",
       "\n",
       "   genre_no  \n",
       "0         0  \n",
       "1         3  \n",
       "2         3  \n",
       "4         1  \n",
       "6         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new colum genre_no to have encoded labels\n",
    "genre_books['genre_no']= le.transform(list(genre_books['genre']))\n",
    "genre_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Children's literature\", 'Fantasy', 'Mystery', 'Novel', 'Science Fiction']\n"
     ]
    }
   ],
   "source": [
    "target_names =list(le.inverse_transform([0,1,2,3,4]))\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorization\n",
    "To convert a collection of raw documents of book summaries to a matrix of TF-IDF features by building a vocabulary that only consider the top  5000 max_features (5000 most frequent words from summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8954, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "X = vectorizer.fit_transform(genre_books.summary).toarray()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7163, 5000)\n",
      "(7163,)\n",
      "(1791, 5000)\n",
      "(1791,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X,genre_books['genre_no'], test_size=0.2, random_state=142)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "lr= LogisticRegression()\n",
    "\n",
    "# Train the model with the training data\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on testing data\n",
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.68      0.46      0.55       237\n",
      "              Fantasy       0.72      0.76      0.74       453\n",
      "              Mystery       0.73      0.64      0.68       271\n",
      "                Novel       0.60      0.76      0.67       430\n",
      "      Science Fiction       0.76      0.70      0.73       400\n",
      "\n",
      "             accuracy                           0.69      1791\n",
      "            macro avg       0.70      0.67      0.68      1791\n",
      "         weighted avg       0.70      0.69      0.69      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's predicting is good on Fantasy,Mystery,Novel and Science Fiction but comparatively less on Chidren's literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_acc_score = accuracy_score(y_test,y_test_pred)\n",
    "logistic_pre_score = precision_score(y_test,y_test_pred, average=\"macro\")\n",
    "logistic_rec_score = recall_score(y_test,y_test_pred, average=\"macro\")\n",
    "logistic_f1_score = f1_score(y_test,y_test_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic regression model : \n",
      "\n",
      "Accuracy score:  0.6901172529313233\n",
      "Precision score:  0.6987587497426926\n",
      "Recall score:  0.6653546861264455\n",
      "F1 score:  0.6750389855483461\n"
     ]
    }
   ],
   "source": [
    "print(\"For Logistic regression model : \")\n",
    "print()\n",
    "print(\"Accuracy score: \", logistic_acc_score)\n",
    "print(\"Precision score: \", logistic_pre_score)\n",
    "print(\"Recall score: \", logistic_rec_score)\n",
    "print(\"F1 score: \", logistic_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model is approximately 70% accurate for predicting genre of a book based on a summary.\n",
    "Precision score is about 0.70 which means, for all instances classified positive (ratio of true positives to the sum of true and false positives), 70% genres were classified correctly.\n",
    "Recall score is 0.66 which means, for all instances that were actually positive (ratio of true positives to the sum of true positives and false negatives), 66% genres were classified correctly.\n",
    "F1 score is about 0.67 which is weighted harmonic mean of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Logistic regression model : \n",
      "\n",
      "Confusion matrix on testing data: \n",
      "[[110  47  13  59   8]\n",
      " [ 18 346  10  45  34]\n",
      " [  5  19 173  63  11]\n",
      " [ 19  21  26 327  37]\n",
      " [  9  45  15  51 280]]\n"
     ]
    }
   ],
   "source": [
    "print(\"For Logistic regression model : \")\n",
    "print()\n",
    "print(\"Confusion matrix on testing data: \")\n",
    "print(confusion_matrix(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled book genres out of a total 1791 test genres : 555\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled book genres out of a total %d test genres : %d\"  % (X_test.shape[0], (y_test != y_test_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modelling using Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on testing data\n",
    "y_test_pred2= gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.41      0.44      0.42       237\n",
      "              Fantasy       0.70      0.59      0.64       453\n",
      "              Mystery       0.53      0.58      0.55       271\n",
      "                Novel       0.49      0.52      0.51       430\n",
      "      Science Fiction       0.62      0.62      0.62       400\n",
      "\n",
      "             accuracy                           0.56      1791\n",
      "            macro avg       0.55      0.55      0.55      1791\n",
      "         weighted avg       0.57      0.56      0.56      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred2,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's predicting is good on Fantasy,Mystery and Science Fiction but comparatively less on Chidren's literature and Novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_acc_score = accuracy_score(y_test,y_test_pred2)\n",
    "nb_pre_score = precision_score(y_test,y_test_pred2, average=\"macro\")\n",
    "nb_rec_score = recall_score(y_test,y_test_pred2, average=\"macro\")\n",
    "nb_f1_score = f1_score(y_test,y_test_pred2, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Naive Bayes model : \n",
      "\n",
      "Accuracy score:  0.5589056393076494\n",
      "Precision score:  0.5495513060151398\n",
      "Recall score:  0.5503620863380837\n",
      "F1 score:  0.5485895110421655\n"
     ]
    }
   ],
   "source": [
    "print(\"For Naive Bayes model : \")\n",
    "print()\n",
    "print(\"Accuracy score: \", nb_acc_score)\n",
    "print(\"Precision score: \", nb_pre_score)\n",
    "print(\"Recall score: \", nb_rec_score)\n",
    "print(\"F1 score: \", nb_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes model is approximately 55% accurate for predicting genre of a book based on a summary.\n",
    "Precision score is about 0.55 which means, for all instances classified positive (ratio of true positives to the sum of true and false positives), 55% genres were classified correctly.\n",
    "Recall score is 0.55 which means, for all instances that were actually positive (ratio of true positives to the sum of true positives and false negatives), 55% genres were classified correctly.\n",
    "F1 score is about 0.54 which is weighted harmonic mean of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Naive Bayes model : \n",
      "\n",
      "Confusion matrix on testing data: \n",
      "[[105  34  29  49  20]\n",
      " [ 54 266  28  45  60]\n",
      " [ 20  16 156  59  20]\n",
      " [ 61  25  65 224  55]\n",
      " [ 19  40  15  76 250]]\n"
     ]
    }
   ],
   "source": [
    "print(\"For Naive Bayes model : \")\n",
    "print()\n",
    "print(\"Confusion matrix on testing data: \")\n",
    "print(confusion_matrix(y_test,y_test_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled book genres out of a total 1791 test genres : 790\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled book genres out of a total %d test genres : %d\"  % (X_test.shape[0], (y_test != y_test_pred2).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling using Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on testing data\n",
    "y_test_pred3= dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.30      0.29      0.29       237\n",
      "              Fantasy       0.53      0.59      0.55       453\n",
      "              Mystery       0.45      0.44      0.45       271\n",
      "                Novel       0.43      0.45      0.44       430\n",
      "      Science Fiction       0.53      0.45      0.49       400\n",
      "\n",
      "             accuracy                           0.46      1791\n",
      "            macro avg       0.45      0.44      0.44      1791\n",
      "         weighted avg       0.46      0.46      0.46      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred3,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's predicting is good on Fantasy,Mystery,Novel and Science Fiction but comparatively less on Chidren's literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_acc_score = accuracy_score(y_test,y_test_pred3)\n",
    "dt_pre_score = precision_score(y_test,y_test_pred3, average=\"macro\")\n",
    "dt_rec_score = recall_score(y_test,y_test_pred3, average=\"macro\")\n",
    "dt_f1_score = f1_score(y_test,y_test_pred3, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Decision tree model : \n",
      "\n",
      "Accuracy score:  0.4617532104969291\n",
      "Precision score:  0.44646701297322106\n",
      "Recall score:  0.443151587312281\n",
      "F1 score:  0.44378456980212544\n"
     ]
    }
   ],
   "source": [
    "print(\"For Decision tree model : \")\n",
    "print()\n",
    "print(\"Accuracy score: \", dt_acc_score)\n",
    "print(\"Precision score: \", dt_pre_score)\n",
    "print(\"Recall score: \", dt_rec_score)\n",
    "print(\"F1 score: \", dt_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree model is approximately 45% accurate for predicting genre of a book based on a summary.\n",
    "Precision,recall and F1 scores are all about 43 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Decision tree model : \n",
      "\n",
      "Confusion matrix on testing data: \n",
      "[[ 68  48  37  60  24]\n",
      " [ 34 266  25  67  61]\n",
      " [ 18  43 120  62  28]\n",
      " [ 68  67  53 193  49]\n",
      " [ 39  82  30  69 180]]\n"
     ]
    }
   ],
   "source": [
    "print(\"For Decision tree model : \")\n",
    "print()\n",
    "print(\"Confusion matrix on testing data: \")\n",
    "print(confusion_matrix(y_test,y_test_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled book genres out of a total 1791 test genres : 964\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled book genres out of a total %d test genres : %d\"  % (X_test.shape[0], (y_test != y_test_pred3).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on testing data\n",
    "y_test_pred4= rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.67      0.24      0.36       237\n",
      "              Fantasy       0.67      0.75      0.71       453\n",
      "              Mystery       0.69      0.55      0.62       271\n",
      "                Novel       0.55      0.78      0.65       430\n",
      "      Science Fiction       0.73      0.69      0.71       400\n",
      "\n",
      "             accuracy                           0.65      1791\n",
      "            macro avg       0.66      0.60      0.61      1791\n",
      "         weighted avg       0.66      0.65      0.63      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred4,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model's predicting is good on Fantasy,Mystery,Novel and Science Fiction but comparatively less on Chidren's literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc_score = accuracy_score(y_test,y_test_pred4)\n",
    "rf_pre_score = precision_score(y_test,y_test_pred4, average=\"macro\")\n",
    "rf_rec_score = recall_score(y_test,y_test_pred4, average=\"macro\")\n",
    "rf_f1_score = f1_score(y_test,y_test_pred4, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest model : \n",
      "\n",
      "Accuracy score:  0.6454494695700725\n",
      "Precision score:  0.6639651075253206\n",
      "Recall score:  0.6021054671756356\n",
      "F1 score:  0.6069177794151943\n"
     ]
    }
   ],
   "source": [
    "print(\"For Random Forest model : \")\n",
    "print()\n",
    "print(\"Accuracy score: \", rf_acc_score)\n",
    "print(\"Precision score: \", rf_pre_score)\n",
    "print(\"Recall score: \", rf_rec_score)\n",
    "print(\"F1 score: \", rf_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model is approximately 63% accurate for predicting genre of a book based on a summary.\n",
    "Precision score is about 0.64 which means, for all instances classified positive (ratio of true positives to the sum of true and false positives), 64% genres were classified correctly.\n",
    "Recall score is 0.58 which means, for all instances that were actually positive (ratio of true positives to the sum of true positives and false negatives), 58% genres were classified correctly.\n",
    "F1 score is about 0.59 which is weighted harmonic mean of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest model : \n",
      "\n",
      "Confusion matrix on testing data: \n",
      "[[ 58  67  17  92   3]\n",
      " [  7 340  10  50  46]\n",
      " [  5  36 150  67  13]\n",
      " [ 11  23  24 334  38]\n",
      " [  5  45  15  61 274]]\n"
     ]
    }
   ],
   "source": [
    "print(\"For Random Forest model : \")\n",
    "print()\n",
    "print(\"Confusion matrix on testing data: \")\n",
    "print(confusion_matrix(y_test,y_test_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled book genres out of a total 1791 test genres : 635\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled book genres out of a total %d test genres : %d\"  % (X_test.shape[0], (y_test != y_test_pred4).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling using KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "knc = KNeighborsClassifier(n_neighbors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=50)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the training data\n",
    "knc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on testing data\n",
    "y_test_pred5= knc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.75      0.03      0.05       237\n",
      "              Fantasy       0.40      0.88      0.55       453\n",
      "              Mystery       0.89      0.13      0.22       271\n",
      "                Novel       0.51      0.54      0.53       430\n",
      "      Science Fiction       0.74      0.53      0.62       400\n",
      "\n",
      "             accuracy                           0.49      1791\n",
      "            macro avg       0.66      0.42      0.39      1791\n",
      "         weighted avg       0.62      0.49      0.44      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred5,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_acc_score = accuracy_score(y_test,y_test_pred5)\n",
    "knc_pre_score = precision_score(y_test,y_test_pred5, average=\"macro\")\n",
    "knc_rec_score = recall_score(y_test,y_test_pred5, average=\"macro\")\n",
    "knc_f1_score = f1_score(y_test,y_test_pred5, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For KNeighborsClassifier model : \n",
      "\n",
      "Accuracy score:  0.49302065884980456\n",
      "Precision score:  0.658376129679567\n",
      "Recall score:  0.42022145920328685\n",
      "F1 score:  0.3917895172156843\n"
     ]
    }
   ],
   "source": [
    "print(\"For KNeighborsClassifier model : \")\n",
    "print()\n",
    "print(\"Accuracy score: \", knc_acc_score)\n",
    "print(\"Precision score: \", knc_pre_score)\n",
    "print(\"Recall score: \", knc_rec_score)\n",
    "print(\"F1 score: \", knc_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier model is approximately 49% accurate for predicting genre of a book based on a summary.\n",
    "Precision score is about 0.65 which means, for all instances classified positive (ratio of true positives to the sum of true and false positives), 65% genres were classified correctly.\n",
    "Recall score is 0.42 which means, for all instances that were actually positive (ratio of true positives to the sum of true positives and false negatives), 42% genres were classified correctly.\n",
    "F1 score is about 0.39 which is weighted harmonic mean of precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For KNeighborsClassifier model : \n",
      "\n",
      "Confusion matrix on testing data: \n",
      "[[  6 141   0  82   8]\n",
      " [  0 399   0  30  24]\n",
      " [  0 156  34  69  12]\n",
      " [  2 160   4 232  32]\n",
      " [  0 150   0  38 212]]\n"
     ]
    }
   ],
   "source": [
    "print(\"For KNeighborsClassifier model : \")\n",
    "print()\n",
    "print(\"Confusion matrix on testing data: \")\n",
    "print(confusion_matrix(y_test,y_test_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled book genres out of a total 1791 test genres : 908\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled book genres out of a total %d test genres : %d\"  % (X_test.shape[0], (y_test != y_test_pred5).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation by visual comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating and comparing the learned predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the list of scores of all the models into respective score variables \n",
    "accuracy_scores = [logistic_acc_score, nb_acc_score, dt_acc_score, rf_acc_score, knc_acc_score]\n",
    "precision_scores = [logistic_pre_score, nb_pre_score, dt_pre_score, rf_pre_score, knc_pre_score]\n",
    "recall_scores = [logistic_rec_score, nb_rec_score, dt_rec_score, rf_rec_score, knc_rec_score]\n",
    "f1_scores = [logistic_f1_score, nb_f1_score, dt_f1_score, rf_f1_score, knc_f1_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the graph\n",
    "plt.figure(figsize=(8,6))\n",
    "ind = np.arange(5) \n",
    "width = 0.15       \n",
    "plt.bar(ind, accuracy_scores , width, label='Accuracy ')\n",
    "plt.bar(ind + width, precision_scores, width, label='Precision')\n",
    "plt.bar(ind + width*2, recall_scores, width, label= 'Recall')\n",
    "plt.bar(ind + width *3, f1_scores, width, label= 'F1 ')\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by modelling')\n",
    "plt.xticks( ind + width*3 / 2 ,('Logistic', 'Naive Bayes', 'Decision tree', 'Random Forest', 'KNeighbors'))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above suggests that the performace of Logistic Regression model is better than every other model on the  book summaries data for predicting genre of a book based on a summary where all scores (accuracy,precision,recall,f1) are approximately 0.7 . The performace of Random forest model on data is second best followed by Gaussian Naive Bayes and KNeighbors Classifier. Decision tree model performance using book summary in predicting genres of book is the least amongst the five models.\n",
    "From classification reports for all models, we can say that model's predicting is good on Fantasy,Mystery,Novel and Science Fiction but comparatively less on Chidren's literature.Which means predicting genre of Chidren's literature is a less precise based on the book summary as compared to other book genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "Since we have used default or estimated values for building the models and not performed cross validation process (for example- to find optimal n_neighbors in KNeighbors), there might be some inaccuracies in predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
